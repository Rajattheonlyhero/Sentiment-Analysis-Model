# -*- coding: utf-8 -*-
"""TensorFlow with GPU

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/gpu.ipynb

# Tensorflow with GPU

This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.

## Enabling and testing the GPU

First, you'll need to enable GPUs for the notebook:

- Navigate to Editâ†’Notebook Settings
- select GPU from the Hardware Accelerator drop-down

Next, we'll confirm that we can connect to the GPU with tensorflow:
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

"""## Observe TensorFlow speedup on GPU relative to CPU

This example constructs a typical convolutional neural network layer over a
random image and manually places the resulting ops on either the CPU or the GPU
to compare execution speed.
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf
print(tf.__version__)

!pip uninstall tensorflow

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

!pip install tensorflow-gpu

!nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals
!pip install tf-nightly
import tensorflow as tf
import os
import datetime
import tensorflow_datasets as tfds
# %load_ext tensorboard

import pkg_resources
for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins'):
  print(entry_point.dist)

!rm -r /usr/local/lib/python3.7/dist-packages/tensorboard/

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

!nvidia-smi

print(tf.__version__)

tf.config.experimental.list_physical_devices()

dataset,info = tfds.load('amazon_us_reviews/Mobile_Electronics_v1_00',with_info=True)

train_dataset=dataset['train']

info

print(train_dataset)
len(list(train_dataset))
BUFFER_SIZE=30000
BATCH_SIZE=256

train_dataset=train_dataset.shuffle(BUFFER_SIZE,reshuffle_each_iteration=False)

for reviews in train_dataset.take(2):
  print(reviews)

for reviews in train_dataset.take(10):
  review_text=reviews['data']
  print(review_text.get('review_body').numpy())
  print(review_text.get('star_rating'))
  print(tf.where(review_text.get('star_rating')>3,1,0).numpy())

tokenizer = tfds.deprecated.text.Tokenizer()

vocabulary_set= set()
for _, reviews in train_dataset.enumerate():
  review_text=reviews['data']
  reviews_tokens=tokenizer.tokenize(review_text.get('review_body').numpy())
  vocabulary_set.update(reviews_tokens)

vocab_size=len(vocabulary_set)
vocab_size

encoder=tfds.deprecated.text.TokenTextEncoder(vocabulary_set)

print(vocabulary_set)

for reviews in train_dataset.take(5):
  review_text=reviews['data']
  print(review_text.get('review_body').numpy())
  encoded_example=encoder.encode(review_text.get('review_body').numpy())
  print(encoded_example)

for index in encoded_example:
  print('{} ----> {}'.format(index,encoder.decode([index])))

def encode(text_tensor,label_tensor):
  encoded_text=encoder.encode(text_tensor.numpy())
  label=tf.where(label_tensor>3,1,0)
  return encoded_text, label

def encode_map_fn(tensor):
  text =tensor['data'].get('review_body')
  label=tensor['data'].get('star_rating')

  encoded_text, label =tf.py_function(encode,inp=[text,label],Tout=(tf.int64,tf.int32))

  encoded_text.set_shape([None])
  label.set_shape([])

  return encoded_text, label

ar_encoded_data=train_dataset.map(encode_map_fn)

for f0,f1 in ar_encoded_data.take(2):
  print(f0)
  print(f1)

TAKE_SIZE=10000

train_data = ar_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)
train_data = train_data.padded_batch(BATCH_SIZE)

test_data = ar_encoded_data.take(TAKE_SIZE)
test_data = test_data.padded_batch(BATCH_SIZE)
vocab_size+=1

sample_text,sample_labels=next(iter(test_data))

sample_text[0],sample_labels[0] 

for f0,f1 in test_data.take(10):
  print(tf.unique_with_counts(f1)[2].numpy())

model=tf.keras.Sequential()
model.add(tf.keras.layers.Embedding(vocab_size,128))
model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True)))
model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))
for units in [64,64]:
  model.add(tf.keras.layers.Dense(units,activation='relu'))
model.add(tf.keras.layers.Dense(1))

!rm -r /tmp/logs

logdir=os.path.join("/tmp/logs",datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir,histogram_freq=1)
checkpointer=tf.keras.callbacks.ModelCheckpoint(filepath='/tmp/sentiment_analysis.tf',verbose=1, save_best_only=True)

model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=['accuracy'])

history=model.fit(train_data,epochs=4,validation_data=test_data,callbacks=[tensorboard_callback, checkpointer])

model.save('/tmp/final_sentiment_analysis.tf')

!ls -alrt /tmp/*.tf

eval_loss, eval_acc = model.evaluate(test_data)

print('\nEval Loss: {:.3f}, Eval Accuracy: {:.3f}'.format(eval_loss,eval_acc))

for f0,f1 in test_data.take(1):
  print(f1)
  print(model.predict(f0))

model.layers

model.summary()

model.get_layer('embedding').output

import matplotlib.pyplot as plt

def plot_graphs(history, metric):
  plt.plot(history.history[metric])
  plt.plot(history.history['val_'+metric],'')
  plt.xlabel("Epochs")
  plt.ylabel(metric)
  plt.legend([metric,'val_'+metric])
  plt.show()

plot_graphs(history, 'accuracy')

plot_graphs(history,'loss')

tf.keras.backend.clear_session()
sa_load=tf.keras.models.load_model('/tmp/sentiment_analysis.tf',compile=False)

def pad_to_size(vec,size):
  zeros=[0]*(size - len(vec))
  vec.extend(zeros)
  return vec

def predict_fn(pred_text):
  encoded_pred_text =encoder.encode(pred_text)
  #print(encoded_pred_text)
  encoded_pred_text=pad_to_size(encoded_pred_text,32)
  #print(encoded_pred_text)
  encoded_pred_text =tf.cast(encoded_pred_text,tf.float32)
  predictions=sa_load.predict(tf.expand_dims(encoded_pred_text, 0))

  return (predictions)

pred_text = ('This watch is pretty bad. Color and dial looks pathetic.')
predictions = predict_fn(pred_text)
print(predictions)

pred_text = ('Amazing product. Fast Delivery. Nice Packing')
predictions = predict_fn(pred_text)
print(predictions)

print(tf.distribute.get_strategy())

def askuser(rev):
  predictions =predict_fn(rev)
  if (predictions.tolist()[0][0])> 1:
    print('Positive Review')
  elif (predictions.tolist()[0][0])< -1:
    print('Negative Review')
  else:
    print('Neutral Review')
ques=input()
try:
  askuser(ques)
except:
  print('Not Meaningful Words')

!nvidia-smi

